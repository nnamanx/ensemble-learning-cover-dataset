{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452f1f9e",
   "metadata": {},
   "source": [
    "# 1. Voting Classifier\n",
    "#### In this assignment, you are expected to build an ensemble of different models and train it on cover type dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a059f",
   "metadata": {},
   "source": [
    "## 1.1. Load dataset\n",
    "#### You will need to read the data from the file (cover.csv). It contains 581012 samples and 54 attributes for each sample. The target column is Cover_Type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21910fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c224e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cover.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a76316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_31  Soil_Type_32  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  Soil_Type_37  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_38  Soil_Type_39  Cover_Type  \n",
       "0           0.0           0.0           5  \n",
       "1           0.0           0.0           5  \n",
       "2           0.0           0.0           2  \n",
       "3           0.0           0.0           2  \n",
       "4           0.0           0.0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5736593",
   "metadata": {},
   "source": [
    "## 1.2. Prepare dataset\n",
    "#### Split the data into train, validation, and test sets using train_test_split twice with 0.2 test_size. Your final distribution will be 371847-92962-116203."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622b0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proportion = 0.2\n",
    "validation_proportion_of_remaining = 0.2\n",
    "validation_proportion_of_total = test_proportion * validation_proportion_of_remaining / (1 - test_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2651159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Cover_Type', axis=1)\n",
    "y = df['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d08fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_remaining, x_test, y_remaining, y_test = train_test_split(x, y, test_size = test_proportion, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_remaining, y_remaining, test_size = validation_proportion_of_total, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd1e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 441568 samples\n",
      "Validation set has 23241 samples\n",
      "Test set has 116203 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set has {x_train.shape[0]} samples\")\n",
    "print(f\"Validation set has {x_val.shape[0]} samples\")\n",
    "print(f\"Test set has {x_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3e4b3",
   "metadata": {},
   "source": [
    "## 1.3. Modeling\n",
    "#### Train 4-5 different classifiers on the data. You can train RandomForestClassifier, ExtraTreesClassifier, LinearSVC, SGDClassifier, MLPClassifier, etc. Evaluate their performances using validation set. Note that training may take quite a while (up to 30 minutes) depending on the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54626e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs = -1, random_state = 42),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(n_jobs = -1, random_state = 42),\n",
    "    \"LinearSVC\": LinearSVC(max_iter = 10000, dual = False, random_state = 42),\n",
    "    \"SGDClassifier\": SGDClassifier(max_iter = 2000, tol = 1e-3, n_jobs = -1, random_state = 42),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter = 300, random_state = 42) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677d13ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier...\n",
      "RandomForestClassifier validation accuracy is 0.9544770018501786\n",
      "Training ExtraTreesClassifier...\n",
      "ExtraTreesClassifier validation accuracy is 0.9530570973710254\n",
      "Training LinearSVC...\n",
      "LinearSVC validation accuracy is 0.7092207736328041\n",
      "Training SGDClassifier...\n",
      "SGDClassifier validation accuracy is 0.5627985026461856\n",
      "Training MLPClassifier...\n",
      "MLPClassifier validation accuracy is 0.7837872724925777\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"{name} validation accuracy is {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a0eaa",
   "metadata": {},
   "source": [
    "## 1.4. Ensembling\n",
    "#### Create a hard and soft voting classifier using the models you have trained. You can use VotingClassifier. Check its performance on the validation set. Do you get better or worse performance than any of the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd04a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_for_soft_voting = {name: clf for name, clf in classifiers.items() if name != \"LinearSVC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8278b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training hard voting...\n",
      "Hard voting classifier validation accuracy is 0.8747041865668431\n"
     ]
    }
   ],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [(name, clf) for name, clf in classifiers.items()], voting = 'hard')\n",
    "print(\"Training hard voting...\")\n",
    "voting_clf_hard.fit(x_train, y_train)\n",
    "y_val_pred_hard = voting_clf_hard.predict(x_val)\n",
    "accuracy_hard = accuracy_score(y_val, y_val_pred_hard)\n",
    "print(f\"Hard voting classifier validation accuracy is {accuracy_hard}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c661d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training soft voting...\n",
      "Soft voting classifier validation accuracy is 0.9118368400671227\n"
     ]
    }
   ],
   "source": [
    "class_for_soft_voting['SGDClassifier'] = SGDClassifier(loss = 'log_loss', max_iter = 2000, tol = 1e-3, n_jobs = -1, random_state = 42)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators = [(name, clf) for name, clf in class_for_soft_voting.items()], \n",
    "    voting = 'soft'\n",
    ")\n",
    "\n",
    "print(\"Training soft voting...\")\n",
    "voting_clf_soft.fit(x_train, y_train) \n",
    "y_val_pred_soft = voting_clf_soft.predict(x_val)  \n",
    "accuracy_soft = accuracy_score(y_val, y_val_pred_soft)  \n",
    "print(f\"Soft voting classifier validation accuracy is {accuracy_soft}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e59247",
   "metadata": {},
   "source": [
    "#### Check if any of the models hurts the performance of the ensemble. You can access the estimators of the ensemble using estimators_ attribute. If so, drop those using set_params and reevaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27acbb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_hard_accuracy = accuracy_score(y_val, voting_clf_hard.predict(x_val))\n",
    "ensemble_soft_accuracy = accuracy_score(y_val, voting_clf_soft.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c7893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble hard voting accuracy is 0.8747041865668431\n",
      "Ensemble soft voting accuracy is 0.9118368400671227\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ensemble hard voting accuracy is {ensemble_hard_accuracy}\")\n",
    "print(f\"Ensemble soft voting accuracy is {ensemble_soft_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71f8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Removing: RandomForestClassifier\n",
      "Performance after removing RandomForestClassifier: 87.47%\n",
      "Removing RandomForestClassifier hurts performance, it should not be dropped\n",
      "2. Removing: ExtraTreesClassifier\n",
      "Performance after removing ExtraTreesClassifier: 87.47%\n",
      "Removing ExtraTreesClassifier hurts performance, it should not be dropped\n",
      "3. Removing: LinearSVC\n",
      "Performance after removing LinearSVC: 87.47%\n",
      "Removing LinearSVC hurts performance, it should not be dropped\n",
      "4. Removing: SGDClassifier\n",
      "Performance after removing SGDClassifier: 87.47%\n",
      "Removing SGDClassifier hurts performance, it should not be dropped\n",
      "5. Removing: MLPClassifier\n",
      "Performance after removing MLPClassifier: 87.47%\n",
      "Removing MLPClassifier hurts performance, it should not be dropped\n"
     ]
    }
   ],
   "source": [
    "hard_remaining = []\n",
    "\n",
    "original_estimators = [(estimator.__class__.__name__, estimator) for estimator in voting_clf_hard.estimators_]\n",
    "\n",
    "for i, (name, estimator) in enumerate(original_estimators):\n",
    "    del voting_clf_hard.estimators_[i]\n",
    "    print(f\"{i+1}. Removing: {name}\")\n",
    "\n",
    "    voting_clf_hard.fit(x_train, y_train)\n",
    "    \n",
    "    new_hard_voting_pred = voting_clf_hard.predict(x_val)\n",
    "    new_hard_voting_acc = accuracy_score(y_val, new_hard_voting_pred)\n",
    "    print(f\"Performance after removing {name}: {new_hard_voting_acc:.2%}\")\n",
    "    \n",
    "    if new_hard_voting_acc <= accuracy_hard:\n",
    "        hard_remaining.append((name, estimator))\n",
    "        print(f\"Removing {name} hurts performance, it should not be dropped\")\n",
    "    else:\n",
    "        print(f\"Removing {name} does not hurt performance, it can be dropped\")\n",
    "    \n",
    "    voting_clf_hard.estimators_.insert(i, estimator)\n",
    "\n",
    "voting_clf_hard.estimators_ = [est for _, est in original_estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18c22b",
   "metadata": {},
   "source": [
    "# 2. Random Forest\n",
    "#### In this assignment, you are expected to build a random forest that classifies a toy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436fb8e",
   "metadata": {},
   "source": [
    "## 2.1. Load dataset\n",
    "#### You will need to read the data from the file (data.csv). It contains 15000 samples and two features for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b69b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77451976",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data.csv'\n",
    "dt = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947a961",
   "metadata": {},
   "source": [
    "## 2.2. Prepare dataset\n",
    "#### Split the data into train and test sets with 0.2 test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "120b11fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (11999, 3)\n",
      "Test set shape: (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(dt, test_size = 0.2, random_state = 42)\n",
    "print(f\"Training set shape: {train_set.shape}\")\n",
    "print(f\"Test set shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e4122",
   "metadata": {},
   "source": [
    "## 2.3. Modeling\n",
    "#### Train a DecisionTreeClassifier on the data. Use GridSearchCV to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057e4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop('1.000000000000000000e+02', axis = 1).to_numpy() \n",
    "Y = dt['1.000000000000000000e+02'].to_numpy()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2154c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, Y_train)\n",
    "parameters = {\n",
    "    'max_depth': range(2, 10), \n",
    "    'min_samples_split': range(2, 10), \n",
    "    'min_samples_leaf': range(2, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86fbe134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 10),\n",
       "                         &#x27;min_samples_leaf&#x27;: range(2, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(2, 10)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(2, 10),\n",
       "                         &#x27;min_samples_leaf&#x27;: range(2, 10),\n",
       "                         &#x27;min_samples_split&#x27;: range(2, 10)},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': range(2, 10),\n",
       "                         'min_samples_leaf': range(2, 10),\n",
       "                         'min_samples_split': range(2, 10)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(dt_clf, parameters, cv = 5, scoring = 'accuracy') \n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1ab53",
   "metadata": {},
   "source": [
    "#### Train the best model on the whole train set (do you need to?) and evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2a9e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the best model: 85.50%\n"
     ]
    }
   ],
   "source": [
    "best_cls = DecisionTreeClassifier(**grid_search.best_params_) \n",
    "best_cls.fit(X_train, Y_train)\n",
    "predict_y = best_cls.predict(X_test) \n",
    "best_accuracy = accuracy_score(Y_test, predict_y)\n",
    "print(f'Accuracy score of the best model: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758136a4",
   "metadata": {},
   "source": [
    "#### Generate 1,200 subsets of the training set, each containing 100 randomly chosen instances. You can use ShuffleSplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c62be875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit \n",
    "\n",
    "s = ShuffleSplit(n_splits=1200, train_size = 100, random_state = 42)\n",
    "\n",
    "X_subsets = []\n",
    "Y_subsets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd968b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, _ in s.split(X_train):\n",
    "    X_subset = X_train[train_index]\n",
    "    Y_subset = Y_train[train_index]\n",
    "    X_subsets.append(X_subset)\n",
    "    Y_subsets.append(Y_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "187d69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X subsets: 1200\n",
      "Y subsets: 1200\n"
     ]
    }
   ],
   "source": [
    "print('X subsets:', len(X_subsets))\n",
    "print('Y subsets:', len(Y_subsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d537aa",
   "metadata": {},
   "source": [
    "#### Train one tree on each subset, using the best model you previously found. Evaluate the performance of the trees using the test set. Did you get lower or higher accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f6c08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1bab035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 81.87%\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "trees = []\n",
    "\n",
    "for X_subset, Y_subset in zip(X_subsets, Y_subsets):\n",
    "    dt_subset = DecisionTreeClassifier(**grid_search.best_params_)\n",
    "    dt_subset.fit(X_subset, Y_subset)\n",
    "    trees.append(dt_subset)\n",
    "    \n",
    "    Y_pred_subset = dt_subset.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, Y_pred_subset)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(f'Mean accuracy: {mean_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01475c22",
   "metadata": {},
   "source": [
    "#### For each instance in the test set, predict its class using 1200 trees, and keep only the most frequent prediction. You can use mode from scipy.stats. Evaluate these predictions. Did you get lower or higher accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f893b4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All trees accuracy: 49.93%\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "for tree in trees:\n",
    "    tree_test_preds = tree.predict(X_test) \n",
    "    test_preds.append(tree_test_preds)\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "test_preds_mode = mode(test_preds, axis=0).mode[0]\n",
    "all_trees_accuracy = np.sum(test_preds_mode.ravel() == Y_test) / len(Y_test)\n",
    "\n",
    "print(f\"All trees accuracy: {all_trees_accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
